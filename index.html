<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3JLBSZZEVM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-T9MWK0XS05');
</script>
	
<title>Tamar Rott Shaham</title>

<meta name="author" content="Tamar Rott Shaham">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="stylesheet.css">
<link rel="icon" type="image/png" href="images/icon4.png">

</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:left;">
                <name>Tamar Rott Shaham</name>
              </p>
              <p style="text-align:justify; margin-top:30px">
                I am a postdoctoral fellow with <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a> at <a href="https://www.csail.mit.edu/">CSAIL, MIT</a>. I did my PhD at the <a href="https://vee.technion.ac.il/">Electrical & Computer Engineering</a> faculty of the <a href="https://www.technion.ac.il/en/home-2/">Technion</a> where I worked with <a href="https://tomer.net.technion.ac.il/"> Tomer Michaeli</a>. 
			        </p>
			        <p style="text-align:justify;">
                My research interests focus on understanding, controlling, and enhancing AI models. I develop tools that automatically discover and explain the internal operations of machine-learning models and use gained insights to control model behavior, enhance performance, and prevent undesired outcomes.
			        </p>
              <p>
			          Office:      45-733D 
              </p>
              <p>
			          Office hours: I'm hosting pro bono office hours, <a href="#pro-bono">here</a> are more details.
              </p>
              <p style="text-align:center; margin-top:30px; margin-bottom:0px">
                <a href="mailto:tamarott@mit.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.il/citations?user=YRJ-ePMAAAAJ&hl">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/TamarRottShaham">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/tamarott">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:27%;max-width:40%">
              <img 
              src="images/TamarRottShaham.jpg" 
              srcset="images/TamarRottShaham_small.jpg 480w, images/TamarRottShaham.jpg 1024w" 
              sizes="(max-width: 768px) 100vw, 50vw" 
              alt="profile photo" 
              loading="lazy" 
              style="width:100%;max-width:100%;height:auto;">
            </a>
            </td>
          </tr>
        </tbody></table>
		
		<hr>
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding-left:20px;padding-bottom:10px;width:100%;vertical-align:middle">
          <heading>News</heading>
			  </td>
      </tr>
			</tbody>
    </table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>		
      <tr>
        <td style="padding:20px;width:1000%;vertical-align:top">
          <p style="text-align:left;margin-top: -10px;">
            <em> [Nov 2024] </em> Check out <a href="https://yael-vinker.github.io/sketch-agent/">SketchAgent</a>, a language-driven agent that create and refine sketches through interactions with users.
          </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [April 2024] </em> We introduce <a href="https://multimodal-interpretability.csail.mit.edu/maia/">MAIA</a>, a <b>M</b>ultimodal <b>A</b>utomated <b>I</b>nterpretability <b>A</b>gent that solves interpretability tasks by iteratively designing experiments on other AI systems.
          </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [Feb 2024] </em> Why does fine-tuning LLMs work so well? <a href="https://finetuning.baulab.info/">Our ICLR'24 paper</a> reveals it's not about introducing new mechanisms but enhancing the existing ones!
          </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [Jan 2024] </em> Check out our new paper: <a href="https://arxiv.org/abs/2401.01862">A Vision Check-up for Language Models</a>, to be presented at CVPR'24!
          </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [Dec 2023] </em> <a href="https://news.mit.edu/2024/ai-agents-help-explain-other-ai-systems-0103">MIT News</a> covers our recent work on Automated Interpretability Agents (AIAs)
          </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [Sep 2023] </em> <a href="https://multimodal-interpretability.csail.mit.edu/FIND-benchmark/">FIND</a> a new benchmark for evaluating automated interpretability methods, was accepted to NeurIPS!
          </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [June 2023] </em> <a href="https://openaccess.thecvf.com/content/CVPR2023W/GCV/papers/Alkobi_Internal_Diverse_Image_Completion_CVPRW_2023_paper.pdf">Internal Diverse Image Completion</a> is presented by Noa at CVPR
          </p>
          <p style="text-align:left;margin-top: -10px;">
          <em> [Dec 2022] </em> SinGAN follow up paper <a href="https://arxiv.org/pdf/2212.01589.pdf">BlendGAN</a> for smooth image blending across time and space
          </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [Sep 2022] </em> I joined <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a>'s lab as a postdoc
            </p>
          <p style="text-align:left;margin-top: -10px;">
            <em> [Oct 2021] </em> Our paper <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Jakoel_GANs_Spatial_Control_via_Inference-Time_Adaptive_Normalization_WACV_2022_paper.pdf">GANs Spatial Control via Inference-Time Adaptive Normalization</a> was accepted to WACV
          </p>
          <p style="text-align:left;margin-top: -10px;">
          <em> [Sep 2021] </em> Our works on <a href="https://openreview.net/pdf?id=XmHnJsiqw9s">single audio generative model</a> and <a href="https://openreview.net/pdf?id=R6nFQy2vwQq">deep self-dissimilarities</a> were accepted to NeurIPS
          </p>
          <p style="text-align:left;margin-top: -10px;">
          <em> [Jun 2021] </em> Check out our new  <a href="https://openreview.net/pdf?id=XmHnJsiqw9s">paper</a> about learning a generative model from a single short audio source
          </p>
          <p style="text-align:left;margin-top: -10px;">
          <em> [Mar 2021] </em> Our  <a href="https://tamarott.github.io/ASAPNet_web/">ASAPNet paper</a>  was accepted to CVPR
          </p>
          <p style="text-align:left; margin-top: -10px;">
          <em> [Oct 2020] </em> I participated in the <a href="https://www.imvc.co.il/">IMVC2020</a>'s GANs panel
          </p>
          <p style="text-align:left; margin-top: -10px;">
          <em> [Aug 2020] </em> We are organizing the <a href="https://sites.google.com/view/deepinternallearning">Deep Internal Learning (DIL)</a> workshop in conjunction with ECCV 2020 (check out my <a href="https://youtu.be/tjxII31RegQ?t=7667">joint keynote</a> with Tomer)
          </p>
          <p style="text-align:left; margin-top: -10px;">
          <em> [Jan 2020] </em> I received the <a href="https://adoberesearch.ctlprojects.com/fellowship/previous-fellowship-award-winners/">Adobe Research Fellowship</a> 
          </p>
          <p style="text-align:left; margin-top: -10px;">
          <em> [Jan 2020] </em> I gave a <a href="https://www.youtube.com/watch?v=j9id4UpN9BI">talk</a> about SinGAN at the Israeli Computer Vision day
          </p>
          <p style="text-align:left; margin-top: -10px;">
          <em> [Nov 2019] </em> <a href="https://tamarott.github.io/SinGAN.htm">SinGAN</a> won <font color=#E65705><b>ICCV’19 Best Paper Award (Marr Prize)!</b></font>
          </p>
          <p style="text-align:left; margin-top: -10px;">
          <em> [Aug 2019] </em> I participated in the Google Student Retreat at London, for <a href="https://www.womentechmakers.com/">Women Techmakers Scholars</a> (now called <a href="https://buildyourfuture.withgoogle.com/scholarships/generation-google-scholarship-emea/">Generation Google Scholarship</a>), and met an amazing group of women from all over Europe, the Middle East and Africa
          </p>
          <p style="text-align:left; margin-top: -10px;">
          <em> [July 2019] </em> I am interning at Adobe Research Seattle for summer 2019, working with <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>, <a href="http://www.mgharbi.com/">Michaël Gharbi</a>, and <a href="https://richzhang.github.io/">Richard Zhang</a>
          </p>
        </td>
      </tr>
    </tbody>
    </table>
		
		<hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding-top:20px;padding-left:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
		
        <table class="responsive-table">
          <tr>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:35%;height:256px;vertical-align:top">
              <div class="one">
                <video  width=200% muted autoplay loop>
                  <source src="./images/SketchAgent_web.mp4" type="video/mp4" loading="lazy">
                  Your browser does not support the video tag.
                </video>
		            <!-- <img src='https://yael-vinker.github.io/sketch-agent/static/SketchAgent.mp4' width="200%"> -->
              </div>
            </td>
            <td style="padding-left:20px;padding-top:20px;padding-bottom:10px;width:25%;vertical-align:top">
              <br>
              <a href="https://yael-vinker.github.io/sketch-agent/">
                <papertitle>SketchAgent: Language-Driven Sequential Sketch Generation</papertitle>
              </a>
              <br>
              <a href="https://yael-vinker.github.io/website/">Yael Vinker</a>,
              <strong>Tamar Rott Shaham</strong>, 
              <a href="https://kristinezheng.github.io/">Kristine Zheng</a>,
              <a href="https://www.linkedin.com/in/alex-zhao-a28b12176/">Alex Zhao</a>,
              <a href="https://profiles.stanford.edu/judith-fan">Judith E Fan</a>,
              <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a>,
              <br>
              <!-- <em>ICML</em>, 2024 -->
              <!-- <br> -->
			        <a href="https://yael-vinker.github.io/sketch-agent/static/source/paper.pdf">paper</a> /
              <a href="https://yael-vinker.github.io/sketch-agent/">web</a> /
              <a href="https://github.com/yael-vinker/SketchAgent">code</a> /
            </td>
          </tr>
          
          <tr>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:35%;height:256px;vertical-align:top">
              <div class="one">
		            <img src='./images/maia_teaser_web.png' width="200%" loading="lazy">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:20px;padding-bottom:10px;width:25%;vertical-align:top">
              <br>
              <a href="https://multimodal-interpretability.csail.mit.edu/maia/">
                <papertitle>A Multimodal Automated Interpretability Agent</papertitle>
              </a>
              <br>
              <strong>Tamar Rott Shaham</strong>*, 
              <a href="https://cogconfluence.com/">Sarah Schwettmann</a>*,              
              <a href="https://frankxwang.github.io/">Franklin Wang</a>,
              <a href="https://twitter.com/AchyutaBot">Achyuta Rajaram</a>,
              <a href="https://evandez.com/">Evan Hernandez</a>,
              <a href="https://www.mit.edu/~jda/">Jacob Andreas</a>,
              <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a>,
              <br>
              <em>ICML</em>, 2024
              <br>
			        <a href="https://arxiv.org/pdf/2404.14394.pdf">paper</a> /
              <a href="https://multimodal-interpretability.csail.mit.edu/maia/">web</a> /
              <a href="https://github.com/multimodal-interpretability/maia/">code</a> /
              <a href="https://multimodal-interpretability.csail.mit.edu/maia/experiment-browser/">experiment browser</a>
            </td>
          </tr>
          
          <tr>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:35%;height:256px;vertical-align:top">
              <div class="one">
		            <img src='./images/finetuning_web.png' width="200%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:35%;vertical-align:top">
              <a href="https://arxiv.org/pdf/2402.14811.pdf">
                <papertitle>Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking</papertitle>
              </a>
              <br>
              <a href="https://nix07.github.io/">Nikhil Prakash</a>,
              <strong>Tamar Rott Shaham</strong>,
              <a href="https://www.linkedin.com/in/tal-haklay-501032192/?originalSubdomain=il">Tal Haklay</a>,
              <a href="https://belinkov.com/">Yonatan Belinkov</a>,
              <a href="https://baulab.info/">David Bau</a>
              <br>
              <em>ICLR</em>, 2024 
              <br>
			        <a href="https://arxiv.org/abs/2402.14811">paper</a> /
              <a href="https://finetuning.baulab.info/">web</a> /
              <a href="https://github.com/Nix07/finetuning">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-top:80px;padding-bottom:50px;width:35%;vertical-align:top">
              <div class="one">
                <!-- <video  width=100% muted autoplay loop>
                  <source src="https://vision-checkup.csail.mit.edu/static/figures/main-figure.mp4" type="video/mp4" width="160">
                  Your browser does not support the video tag.
                </video> -->
                <br>
		            <img src='https://vision-checkup.csail.mit.edu/static/figures/dataset.png' width="200%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:80px;padding-bottom:50px;width:25%;vertical-align:top">
              <a href="https://arxiv.org/pdf/2401.01862.pdf">
                <papertitle>A Vision Check-up for Language Models</papertitle>
              </a>
              <br>
              <a href="https://pratyushasharma.github.io/">Pratyusha Sharma</a>*,
              <strong>Tamar Rott Shaham</strong>*,
              <a href="https://mbaradad.github.io/">Manel Baradad</a>,
              <a href="https://stephanie-fu.github.io/">Stephanie Fu</a>,
              <a href="https://www.linkedin.com/in/adrian-rodriguez-munoz/">Adrián Rodríguez-Muñoz</a>,
              <a href="https://shivamduggal4.github.io/">Shivam Duggal</a>,
              <a href="https://web.mit.edu/phillipi/">Phillip Isola</a>,
              <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a>
              <br>
              <em>CVPR</em>, 2024
              <br>
              <font color=#ED8200><strong>Highlight paper</strong></font>
              <br>
			        <a href="https://arxiv.org/abs/2401.01862">paper</a> /
              <a href="https://vision-checkup.github.io/">web</a>
            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-top:50px;padding-bottom:50px;width:25%;height:306px;vertical-align:top">
              <div class="one">
		            <img src='https://multimodal-interpretability.csail.mit.edu/FIND-benchmark/static/figures/FIND_gif.gif' width="200%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:50px;padding-bottom:50px;width:25%;height:306px;vertical-align:top">
              <br>
              <a href="https://arxiv.org/pdf/2309.03886.pdf">
                <papertitle>FIND: A Function Interpretation Benchmark for Evaluating Interpretability Methods</papertitle>
              </a>
              <br>
              <a href="https://cogconfluence.com/">Sarah Schwettmann</a>*,
              <strong>Tamar Rott Shaham</strong>*, 
              <a href="https://joaanna.github.io/">Joanna Materzynska</a>,
              <a href="https://nchowdhury.com/">Neil Chowdhury</a>,
              <a href="https://people.csail.mit.edu/lishuang/">Shuang Li</a>,
              <a href="https://www.mit.edu/~jda/">Jacob Andreas</a>,
              <a href="https://baulab.info/">David Bau</a>,
              <a href="https://groups.csail.mit.edu/vision/torralbalab/">Antonio Torralba</a>,
              <br>
              <em>NeurIPS</em>, 2023 
              <br>
			        <a href="https://arxiv.org/pdf/2309.03886.pdf">paper</a> /
              <a href="https://multimodal-interpretability.csail.mit.edu/FIND-benchmark/">web</a> /
              <a href="https://github.com/multimodal-interpretability/FIND">code</a>

            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <div class="one">
			          <img src='images/DCM.png' width="150%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;vertical-align:top">
              <a href="https://openreview.net/pdf?id=uoqOpOIp34">
                <papertitle>Discovering Variable Binding Circuitry with Desiderata</papertitle>
              </a>
              <br>
              <a href="https://xanderdavies.com/">Xander Davies</a>*,
              <a href="https://www.maxnadeau.com/">Max Nadeau</a>*,
              <a href="https://nix07.github.io/">Nikhil Prakash</a>*,
              <strong>Tamar Rott Shaham</strong>, 
              <a href="https://baulab.info/">David Bau</a>,
              <br>
              <em>ICML Workshop Deployable Generative AI</em>, 2023 
              <br>
			        <a href="https://openreview.net/pdf?id=uoqOpOIp34">paper</a> /
			        <a href="https://dcm.baulab.info/">web</a> /
              <a href="https://github.com/Nix07/binding-circuit-discovery">code</a> 
            </td>
          </tr>
          
          <tr onmouseout="INT_stop()" onmouseover="INT_start()">
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <div class="one">
                <div class="two" id='int_image'>
                  <img src='images/interior2.png' width="256"></div>
                <img src='images/interior1.png' width="256">
              </div>
              <script type="text/javascript">
                function INT_start() {
                  document.getElementById('int_image').style.opacity = "1";
                }

                function INT_stop() {
                  document.getElementById('int_image').style.opacity = "0";
                }
                INT_stop()
              </script>
            </td>	
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="https://www.mdpi.com/2075-5309/13/7/1793">
                <papertitle>Automation in Interior Space Planning: Utilizing Conditional Generative Adversarial Network Models to Create Furniture Layouts</papertitle>
              </a>
              <br>
              <a href="">Hanan Tanasra</a>,
              <strong>Tamar Rott Shaham</strong>, 
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <a href="https://architecture.technion.ac.il/members/guy-austern-2/">Guy Austern</a>,
              <a href="https://urbanai.fr/ce/shany-barath/">Shany Barath</a>,
              <br>
              <em>Buildings</em>, 2023
              <br>
			        <a href="https://www.mdpi.com/2075-5309/13/7/1793">paper</a> 
            </td>
          </tr>
          
          <tr onmouseout="IDC_stop()" onmouseover="IDC_start()">
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <div class="one">
                <div class="two" id='idc_image'>
                  <img src='images/IDC2.png' width="256"></div>
                <img src='images/IDC1.png' width="256">
              </div>
              <script type="text/javascript">
                function IDC_start() {
                  document.getElementById('idc_image').style.opacity = "1";
                }

                function IDC_stop() {
                  document.getElementById('idc_image').style.opacity = "0";
                }
                IDC_stop()
              </script>
            </td>	
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="https://openaccess.thecvf.com/content/CVPR2023W/GCV/papers/Alkobi_Internal_Diverse_Image_Completion_CVPRW_2023_paper.pdf">
                <papertitle>Internal Diverse Image Completion</papertitle>
              </a>
              <br>
              <a href="">Noa Alkobi</a>,
              <strong>Tamar Rott Shaham</strong>, 
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>CVPR, Generative Models for Computer Vision Workshop</em>, 2023
              <br>
			        <a href="https://openaccess.thecvf.com/content/CVPR2023W/GCV/papers/Alkobi_Internal_Diverse_Image_Completion_CVPRW_2023_paper.pdf">paper</a> 
            </td>
          </tr>

          <tr>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <div class="one">
			          <img src='images/s0_sampled.gif' width="160%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="https://arxiv.org/pdf/2212.01589.pdf">
                <papertitle>BlendGAN: Learning and Blending the Internal Distributions of Single Images by Spatial Image-Identity Conditioning</papertitle>
              </a>
              <br>
              <a href="">Idan Kligvasser</a>,
              <strong>Tamar Rott Shaham</strong>, 
              <a href="">Noa Alkobi</a>,
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>Arxiv</em>, 2022
              <br>
			        <a href="https://arxiv.org/pdf/2212.01589.pdf">paper</a> 
            </td>
          </tr>
		
    <tr onmouseout="AITN_stop()" onmouseover="AITN_start()">
        <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <div class="one">
                <div class="two" id='aitn_image'>
                  <img src='images/aitn_after.png' width="256"></div>
                <img src='images/aitn_before.png' width="256">
              </div>
              <script type="text/javascript">
                function AITN_start() {
                  document.getElementById('aitn_image').style.opacity = "1";
                }

                function AITN_stop() {
                  document.getElementById('aitn_image').style.opacity = "0";
                }
                AITN_stop()
              </script>
            </td>	
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="">
                <papertitle>GANs Spatial Control via Inference-Time Adaptive Normalization</papertitle>
              </a>
              <br>
			  <a href="">Karin Jakoel*</a>,
			  <a href="">Liron Efraim*</a>,
			  <strong>Tamar Rott Shaham</strong>
              <br>
              <em>WACV</em>, 2022
              <br>
			  <a href="https://openaccess.thecvf.com/content/WACV2022/papers/Jakoel_GANs_Spatial_Control_via_Inference-Time_Adaptive_Normalization_WACV_2022_paper.pdf">paper</a> /
			  <a href="https://www.youtube.com/watch?v=GqRXXiaQZCE">video</a> /
			  <a href="https://openaccess.thecvf.com/content/WACV2022/supplemental/Jakoel_GANs_Spatial_Control_WACV_2022_supplemental.pdf">supplementals</a>
            </td>
        </tr>
		
		<tr>
      <td style="padding-left:20px;padding-top:50px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
        <div class="one">
			    <img src='images/CAW.png' width="160%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:50px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="https://galgreshler.github.io/Catch-A-Waveform/">
                <papertitle>Catch-A-Waveform: Learning to Generate Audio from a Single Short Example</papertitle>
              </a>
              <br>
			  <a href="mailto:galgreshler@gmail.com">Gal Greshler</a>,
			  <strong>Tamar Rott Shaham</strong>, 
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>NeurIPS</em>, 2021
              <br>
			  <a href="https://openreview.net/pdf?id=XmHnJsiqw9s">paper</a> /
			  <a href="https://galgreshler.github.io/Catch-A-Waveform/">web</a> /
			  <a href="https://github.com/galgreshler/Catch-A-Waveform">code</a> /
              <a href="https://openreview.net/attachment?id=XmHnJsiqw9s&name=supplementary_material">supplementals</a>
            </td>
        </tr>
		
		<tr>
      <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
        <div class="one">
			    <img src='images/dsd.png' width="140%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="">
                <papertitle>Deep Self-Dissimilarities as Powerful Visual Fingerprints</papertitle>
              </a>
              <br>
			  <a href="">Idan Kligvasser</a>,
			  <strong>Tamar Rott Shaham</strong>, 
			  <a href="https://sites.google.com/view/yuval-bahat/home">Yuval Bahat</a>,
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>NeurIPS</em>, 2021 <br> <font color=#ED8200><strong>Spotlight presentation</strong></font>
              <br>
			  <a href="https://openreview.net/pdf?id=R6nFQy2vwQq">paper</a> /
              <a href="https://openreview.net/attachment?id=R6nFQy2vwQq&name=supplementary_material">supplementals</a>
            </td>
          </tr>
		
          <tr onmouseout="asap_stop()" onmouseover="asap_start()">
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <div class="one">
                <div class="two" id='asap_image'>
                  <img src='images/asap_after.png' width="200"></div>
                <img src='images/asap_before.png' width="200">
              </div>
              <script type="text/javascript">
                function asap_start() {
                  document.getElementById('asap_image').style.opacity = "1";
                }

                function asap_stop() {
                  document.getElementById('asap_image').style.opacity = "0";
                }
                asap_stop()
              </script>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="https://tamarott.github.io/ASAPNet_web/">
                <papertitle>Spatially-Adaptive Pixelwise Networks for Fast Image Translation</papertitle>
              </a>
              <br>
              <strong>Tamar Rott Shaham</strong>, 
			  <a href="http://www.mgharbi.com/">Michaël Gharbi</a>, 
              <a href="https://richzhang.github.io/">Richard Zhang</a>, 
              <a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a>,
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://tamarott.github.io/ASAPNet_web/">project page</a> /
              <a href="https://arxiv.org/pdf/2012.02992.pdf">arXiv</a>
            </td>
          </tr>
		  
		  <tr onmouseout="singan_stop()" onmouseover="singan_start()">
        <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
          <div class="one">
                <div class="two" id='singan_image'>
                  <img src='images/singan_after.png' width="256"></div>
                <img src='images/singan_before.png' width="256">
              </div>
              <script type="text/javascript">
                function singan_start() {
                  document.getElementById('singan_image').style.opacity = "1";
                }

                function singan_stop() {
                  document.getElementById('singan_image').style.opacity = "0";
                }
                singan_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a href="https://tamarott.github.io/SinGAN.htm">
                <papertitle>SinGAN: Learning a generative model from a single natural image</papertitle>
              </a>
              <br>
              <strong>Tamar Rott Shaham</strong>, 
			  <a href="http://people.csail.mit.edu/talidekel/">Tali Dekel</a>, 
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>ICCV</em>, 2019&nbsp <br> <font color=#E65705><strong>Best Paper Award (Marr Prize)</strong></font>
              <br>
              <a href="https://tamarott.github.io/SinGAN.htm">project page</a> /
              <a href="https://arxiv.org/pdf/1905.01164.pdf">arXiv</a> /
			  <a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Shaham_SinGAN_Learning_a_Generative_Model_From_a_Single_Natural_Image_ICCV_2019_paper.pdf">CVF</a> /
			  <a href="https://openaccess.thecvf.com/content_ICCV_2019/supplemental/Shaham_SinGAN_Learning_a_ICCV_2019_supplemental.pdf">supp</a> /
			  <a href="https://github.com/tamarott/SinGAN">code</a> /
			  <a href="https://youtu.be/mdAcPe74tZI?t=3191">ICCV talk</a> /
			  <a href="https://www.youtube.com/watch?v=j9id4UpN9BI">Israel Vision Day talk (recommended)</a>
            </td>
          </tr>
		  
		  <tr onmouseout="dac_stop()" onmouseover="dac_start()">
        <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
          <div class="one">
                <div class="two" id='dac_image'>
                  <img src='images/dac_after.png' width="200"></div>
                <img src='images/dac_before.png' width="200">
              </div>
              <script type="text/javascript">
                function dac_start() {
                  document.getElementById('dac_image').style.opacity = "1";
                }

                function dac_stop() {
                  document.getElementById('dac_image').style.opacity = "0";
                }
                dac_stop()
              </script>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="http://webee.technion.ac.il/people/tomermic/DeformationAwareCompressionWEB/DeformationAwareImageCompression.htm">
                <papertitle>Deformation Aware image Compression</papertitle>
              </a>
              <br>
              <strong>Tamar Rott Shaham</strong>, 
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>CVPR</em>, 2018&nbsp <br> <font color=#ED8200><strong>Spotlight presentation</strong></font>
              <br>
              <a href="http://webee.technion.ac.il/people/tomermic/DeformationAwareCompressionWEB/DeformationAwareImageCompression.htm">project page</a> /
              <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers_backup/Shaham_Deformation_Aware_Image_CVPR_2018_paper.pdf">paper</a> /
			  <a href="https://webee.technion.ac.il/people/tomermic/DeformationAwareCompressionWEB/DeformationAwareCompressionCode.zip">code</a> /
			  <a href="https://youtu.be/giA2rpN3Iv8?t=4060">spotlight</a>
            </td>
          </tr>	  
		  
		  <tr>
        <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
          <div class="one">
			    <img src='images/xUnit.png' width="160%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="">
                <papertitle>xUnit: Learning a Spatial Activation Function for Efficient Image Restoration</papertitle>
              </a>
              <br>
			  <a href="https://scholar.google.co.il/citations?user=a-r4CdYAAAAJ&hl=en">Idan Kligvasser</a>
			  <strong>Tamar Rott Shaham</strong>, 
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>CVPR</em>, 2018&nbsp <br> <font color=#ED8200><strong>Spotlight presentation</strong></font>
              <br>
              <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kligvasser_xUnit_Learning_a_CVPR_2018_paper.pdf">paper</a> /
			  <a href="https://github.com/kligvasser/xUnit">code</a> /
			  <a href="https://www.youtube.com/watch?v=giA2rpN3Iv8&feature=youtu.be&t=3728">spotlight (by Idan)</a>
              <p></p>
            </td>
          </tr> 
		  
		  <tr onmouseout="vip_stop()" onmouseover="vip_start()">
        <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
          <div class="one">
                <div class="two" id='vip_image'><video  width=140% muted autoplay loop>
                <source src="images/vip_after.mp4" type="video/mp4" width="256">
                Your browser does not support the video tag.
                </video></div>
                <!-- <img src='images/vip_before.png' width="256"> -->
              </div>
              <script type="text/javascript">
                function vip_start() {
                  document.getElementById('vip_image').style.opacity = "1";
                }
                vip_start()
              </script>
            </td>
            <td style="padding-left:20px;padding-top:30px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="https://webee.technion.ac.il/people/tomermic/Visualization/VisualizingImagePriors.htm">
                <papertitle>Visualizing Image Priors</papertitle>
              </a>
              <br>
			  <strong>Tamar Rott Shaham</strong>, 
              <a href="https://tomer.net.technion.ac.il/">Tomer Michaeli</a>
              <br>
              <em>ECCV</em>, 2016&nbsp 
              <br>
			  <a href="https://webee.technion.ac.il/people/tomermic/Visualization/VisualizingImagePriors.htm">project page</a> /
              <a href="https://tomer.net.technion.ac.il/files/2017/08/PriorVisualization.pdf">paper</a> /
			  <a href="http://www.eccv2016.org/files/posters/P-4B-36.pdf">poster</a>
            </td>
          </tr>
		  
		  <tr>
        <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
          <div class="one">
				<img src='images/GM.png' width="140%">
              </div>
            </td>
            <td style="padding-left:20px;padding-top:10px;padding-bottom:50px;width:25%;height:256px;vertical-align:top">
              <a href="">
                <papertitle>Edge Preserving Multi-Modal Registration Based On Gradient Intensity Self-Similarity</papertitle>
              </a>
              <br>
			  <strong>Tamar Rott Shaham</strong>, 
              <a href="">Dorin Shriki</a>,
			  <a href="https://www.tau.ac.il/~bendory/index.html">Tamir Bendory</a>
              <br>
              <em>IEEEI</em>, 2014&nbsp 
              <br>
              <a href="http://sipl.eelabs.technion.ac.il/wp-content/uploads/sites/6/2016/09/paper14-Edge-Preserving-Multi-Modal-Registration-Based-on-Gradient-Intensity-Self-Similarity.pdf">paper</a> 
			 </td>
          </tr>
    </tbody></table>

    <hr>
		<table id="pro-bono" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
        <td style="padding-left:20px;padding-bottom:10px;width:100%;vertical-align:middle">
          <h2 id="pro-bono">Pro bono office hour</h2>
			  </td>
			 </tr>
			</tbody></table>
			<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>		
			  <tr>
          <td style="padding:20px;width:1000%;vertical-align:top">
            <p style="text-align: justify; margin-top: -10px;">
              Inspired by <a href="https://krrish94.github.io/">Krishna Murthy</a> and <a href="https://people.csail.mit.edu/weichium/">Wei-Chiu Ma</a>, I dedicate 1-2 hours each week to providing guidance and mentorship to students from underrepresented groups, or to anyone who needs it. Specifically, if you're searching for a postdoc position, I'd be happy to share insights from my experience.
              Please fill out this <a href="https://forms.gle/cuVatvom4xK4FzJ18">form</a> to contact me.
          </p>
        </td>
      </tr>
    </tbody></table>


		<br>
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <p style="margin:0px;text-align:center;font-size:small;">
               Wonder about the <a href="https://www.google.com/search?q=tamar+hebrew+name&sxsrf=ALeKk02L2UjlGPS_VIuIZBhOSVMSx-HBCg%3A1623665194369&ei=KirHYJ2JFpyOjLsP_9-loAQ&oq=tamar+hebrew+name&gs_lcp=Cgdnd3Mtd2l6EAMyBwgjELADECcyBQgAELADMgkIABCwAxAIEB5QAFgAYO7WA2gEcAB4AIABcIgBcJIBAzAuMZgBAKoBB2d3cy13aXrIAQPAAQE&sclient=gws-wiz&ved=0ahUKEwidxpOZ8JbxAhUcB2MBHf9vCUQQ4dUDCA0&uact=5">meaning of <img src='images/icon4.png' width="3%"> </a>? 
              </p>
            </td>
          </tr>
        </tbody></table>
		<hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="margin-top:-20px;text-align:center;font-size:small;">
                This website is based on <a href="https://jonbarron.info/">Jon Barron</a>'s template (<a href="https://github.com/jonbarron/jonbarron_website">source code</a>)
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
